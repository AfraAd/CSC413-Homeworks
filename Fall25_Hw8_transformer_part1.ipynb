{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfraAd/CSC413-Homeworks/blob/main/Fall25_Hw8_transformer_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV4g7YkC25iC"
      },
      "source": [
        "# Homework 8\n",
        "\n",
        "In this homework, you will train a multi-label text classifier on a subset of [AG News](https://huggingface.co/datasets/r-three/ag_news_subset) dataset using a pre-trained BERT model. The AG News dataset consists of news articles categorized into one of four topics (0 - World, 1 - Sports, 2 - Business, 3 - Sci/Tech).\n",
        "\n",
        "**In part 1**, you will fine-tune a BERT-style model on the AG News dataset and evaluate its performance. You can find a tutorial for loading BERT and fine-tuning [here](https://huggingface.co/docs/transformers/training). For simplicity, I recommend using the [Hugging Face Transformers library](https://huggingface.co/docs/transformers/index).You're welcome to use a different framework if you prefer.\n",
        "\n",
        "**In part 2**, instead of fine-tuning a BERT-style model directly, you will use the representations from the BERT-style model as input to a linear classifier. Does this approach perform better or worse?\n",
        "\n",
        "For both part 1 and part 2, your goal is to achieve a test accuracy above the specified thresholds. You won’t have access to the test labels—just like in real-world applications!\n",
        "\n",
        "**Tips about fine-tuning**\n",
        "\n",
        "* Data preprocessing: raw text data should be tokenized before being fed to the model as batches during trainig.\n",
        "* Hyperparameter choices: Experiment with settings such as learning rate, warmup ratio, optimizer, number of training steps, and batch size.\n",
        "* Avoid overfitting: remember that your fine-tuned model will be evaluated on the test set!\n",
        "\n",
        "\n",
        "**!! IMPORTANT NOTE !!**\n",
        "\n",
        "You are free to explore and implement the training code however you want to maximize the model performance. However, please put the code you're running under `if __name__ == '__main__':` so that the particular training step is not run when we later evaluate your final script! Otherwise you may fail the Markus tests due to timeout.\n",
        "\n",
        "```\n",
        "if __name__ == '__main__':\n",
        "    # your training code to fine-tune the model\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYmukJqi_qQl"
      },
      "source": [
        "# Part 1 (4 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edPVKxZtQ0u2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # !pip install datasets\n",
        "    # !pip install evaluate\n",
        "    # !pip install -U sentence-transformers\n",
        "\n",
        "    from datasets import load_dataset, DatasetDict\n",
        "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch\n",
        "    import evaluate\n",
        "\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    import joblib\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "    ################# Import additional packages you need #################\n",
        "    #####################################################################################\n",
        "    import numpy as np\n",
        "    import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwHmIaTUQZYy"
      },
      "outputs": [],
      "source": [
        "################## HELPER CODE FOR SAVING RELEVANT FILES ##################\n",
        "if __name__ == '__main__':\n",
        "    def in_colab():\n",
        "        try:\n",
        "            import google.colab\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "\n",
        "    if in_colab():\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        SAVE_PATH = '/content/drive/MyDrive/CSC413'\n",
        "    else:\n",
        "        SAVE_PATH = '.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MenK8lkBOq3g"
      },
      "source": [
        "## Part 1.a\n",
        "\n",
        "Fine-tune [TinyBERT](https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D) on AG News and evaluate the results. You can find a tutorial for loading BERT and fine-tuning [here](https://huggingface.co/docs/transformers/training). In that tutorial, you will need to change the dataset from `\"yelp_review_full\"` to the correct dataset path and the model from `\"bert-base-uncased\"` to `\"huawei-noah/TinyBERT_General_4L_312D\"`. You'll also need to modify the code since AG New is a four-class classification dataset (unlike the Yelp Reviews dataset, which is a five-class classification dataset).\n",
        "\n",
        "**TODO**\n",
        "* After fine-tuning the model, save model predictions on the test set to *part1_tiny_bert_model_test_prediction.csv*. The csv file should contain \"index\" columns, corresponding to the unique sample index, and \"pred\" column, the model prediction on that sample. Your model should achieve >= 80% on the test accuracy to receive a full mark.\n",
        "\n",
        "```\n",
        "index, pred\n",
        "0,model_pred_value_0\n",
        "1,model_pred_value_1\n",
        "2,model_pred_value_2\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3Zr_lHDWVTU"
      },
      "outputs": [],
      "source": [
        "######################## DO NOT MODIFY THE CODE ########################\n",
        "if __name__ == '__main__':\n",
        "    dataset = load_dataset('r-three/ag_news_subset')\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\", num_labels=4)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
        "    print(dataset[\"train\"][100])\n",
        "\n",
        "    # Tokenization function\n",
        "    def tokenize_function(examples):\n",
        "        texts = [f\"{title} {desc}\" for title, desc in zip(examples['title'], examples['description'])]\n",
        "        return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # Tokenize datasets\n",
        "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    # Metrics\n",
        "    accuracy_metric = evaluate.load(\"accuracy\")\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"{SAVE_PATH}/tinybert_results\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=5e-5,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=64,\n",
        "        num_train_epochs=4,\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        save_strategy = \"epoch\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # Train and save predictions\n",
        "    trainer.train()\n",
        "    test_predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "    test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
        "\n",
        "    pd.DataFrame({'index': range(len(test_preds)), 'pred': test_preds}).to_csv(\n",
        "        f\"{SAVE_PATH}/part1_tiny_bert_model_test_prediction.csv\", index=False\n",
        "    )\n",
        "#########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your prediction is saved in pandas dataframe, you can do something like:\n",
        "```\n",
        "if __name__ == '__main__':\n",
        "   part1_tiny_bert_pred.to_csv(f\"{SAVE_PATH}/part1_tiny_bert_model_test_prediction.csv\", index=False)\n",
        "```"
      ],
      "metadata": {
        "id": "SHieq6Luch21"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JTLJgvUIT46"
      },
      "source": [
        "## Part 1.b\n",
        "\n",
        "For this section, choose a different pre-trained BERT-style model from the [Hugging Face Model Hub](https://huggingface.co/models) and fine-tune it. There are tons of options - part of the homework is navigating the hub to find different models! I recommend picking a model that is smaller than BERT-Base (as TinyBERT is) just to make things computationally cheaper. Is the final validation accuracy higher or lower with this other model?\n",
        "\n",
        "**TODO**\n",
        "* As in part 1.a, save model predictions on the test set to *part1_hf_bert_model_test_prediction.csv*. The csv file should contain \"index\" columns, corresponding to the unique sample index, and \"pred\" column, the model prediction on that sample. Your model should achieve >=80% on the test accuracy to receive a full mark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAw02tJzJDme"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    ############### YOUR CODE ###############\n",
        "    # TODO: find a new HF BERT based model from HuggingFace and load it.\n",
        "    HF_BERT_BASED_MODEL = 'distilbert-base-uncased'\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    print(f\"Loading model: {HF_BERT_BASED_MODEL}\")\n",
        "    model_hf = AutoModelForSequenceClassification.from_pretrained(HF_BERT_BASED_MODEL, num_labels=4)\n",
        "    tokenizer_hf = AutoTokenizer.from_pretrained(HF_BERT_BASED_MODEL)\n",
        "\n",
        "    # Tokenization function for the new model\n",
        "    def tokenize_function_hf(examples):\n",
        "        texts = [f\"{title} {desc}\" for title, desc in zip(examples['title'], examples['description'])]\n",
        "        return tokenizer_hf(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # Tokenize datasets\n",
        "    print(\"Tokenizing datasets with new tokenizer...\")\n",
        "    tokenized_datasets_hf = dataset.map(tokenize_function_hf, batched=True)\n",
        "\n",
        "    # Data collator\n",
        "    data_collator_hf = DataCollatorWithPadding(tokenizer=tokenizer_hf)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args_hf = TrainingArguments(\n",
        "        output_dir=f\"{SAVE_PATH}/hf_bert_results\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=3e-5,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=64,\n",
        "        num_train_epochs=3,\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        logging_steps=100,\n",
        "        save_total_limit=2,\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer_hf = Trainer(\n",
        "        model=model_hf,\n",
        "        args=training_args_hf,\n",
        "        train_dataset=tokenized_datasets_hf[\"train\"],\n",
        "        eval_dataset=tokenized_datasets_hf[\"validation\"],\n",
        "        tokenizer=tokenizer_hf,\n",
        "        data_collator=data_collator_hf,\n",
        "        compute_metrics=compute_metrics,  # Reuse from Part 1.a\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    print(f\"Training {HF_BERT_BASED_MODEL}...\")\n",
        "    trainer_hf.train()\n",
        "\n",
        "    # Evaluate\n",
        "    eval_results_hf = trainer_hf.evaluate()\n",
        "    print(f\"Validation Accuracy: {eval_results_hf['eval_accuracy']:.4f}\")\n",
        "\n",
        "    # Predict on test set\n",
        "    print(\"Generating predictions on test set...\")\n",
        "    test_predictions_hf = trainer_hf.predict(tokenized_datasets_hf[\"test\"])\n",
        "    test_preds_hf = np.argmax(test_predictions_hf.predictions, axis=1)\n",
        "\n",
        "    # Save predictions to CSV\n",
        "    part1_hf_bert_pred = pd.DataFrame({\n",
        "        'index': range(len(test_preds_hf)),\n",
        "        'pred': test_preds_hf\n",
        "    })\n",
        "    part1_hf_bert_pred.to_csv(f\"{SAVE_PATH}/part1_hf_bert_model_test_prediction.csv\", index=False)\n",
        "    print(f\"Saved predictions to {SAVE_PATH}/part1_hf_bert_model_test_prediction.csv\")\n",
        "    #########################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your training code here...**"
      ],
      "metadata": {
        "id": "QP_4e2M4cSz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, you can consider something like:\n",
        "\n",
        "```\n",
        "if __name__ == '__main__':\n",
        "   part1_hf_bert_pred.to_csv(f\"{SAVE_PATH}/part1_hf_bert_model_test_prediction.csv\", index=False)\n",
        "```"
      ],
      "metadata": {
        "id": "jOyGA96Dc65h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yt5QSetH7Vu"
      },
      "source": [
        "# Part 2 (2.5 points)\n",
        "\n",
        "Instead of fine-tuning the full model on a target dataset, it's also possible to use the output representations from a BERT-style model as input to a linear classifier and *only* train the classifier (leaving the rest of the pre-trained parameters fixed). You can do this easily using the [`sentence-transformers`](https://www.sbert.net/) library. Using `sentence-tranformers` gives you back a fixed-length representation of a given text sequence. To achieve this, you need to\n",
        "1. Pick a pre-trained sentence Transformer.\n",
        "2. Load the AG News dataset and feed the text from each example into the model.\n",
        "3. Train a linear classifier on the representations.\n",
        "4. Evaluate performance on the validation set.\n",
        "\n",
        "For the second step, you can learn more about how to use Hugging Face datasets [here](https://huggingface.co/docs/datasets/index). For the third and fourth step, it's possible to either do this directly in PyTorch, or collect the learned representations and use them as feature vectors to train a linear classifier in any other library (e.g. [scikit-learn](https://scikit-learn.org/stable/modules/linear_model.html)). For this homework, you will implement the second approach.\n",
        "\n",
        "After you complete the above steps, is the accuracy on the validation set higher or lower using a fixed sentence Transformer?\n",
        "\n",
        "**TODO**:\n",
        "* Complete the `encode_data` function: the function embeds each text sample into an output representation using the provided sentence encoder. The function is called to map a text data sample to the model representation, as shown below:\n",
        "```\n",
        "dataset.map(lambda x: encode_data(sen_model, x), batched=True)\n",
        "```\n",
        "* Train a Logistic Regression classifier: use sklearn.linear_model.LogisticRegression to fit the model on the encoded text data.\n",
        "* Save your trained model: After training, saved teh fitted logistic regression model as `sentence_encoder_classification.pkl`. Your model should achieve >=85% on the test accuracy to receive a full mark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cym2hkG1WbVE"
      },
      "outputs": [],
      "source": [
        "def encode_data(model, x):\n",
        "    \"\"\"Takes the model and the dataset object\n",
        "        Returns a dictionary consisting of \"encoded_input\" and \"label\" as keys.\n",
        "        - \"encoded_input\" contains the tokenized text features produced by the sentence transformer.\n",
        "        - \"label\" is the target class label for each example.\n",
        "        encoded_input is the encoded text input, and label is the target label.\n",
        "        NOTE: Please assume the dataset object is the original one loaded via\n",
        "              load_dataset('r-three/') for reproducibility.\n",
        "              Which means if you want to create additional features to create the encoded_input,\n",
        "              do so within this function.\n",
        "    \"\"\"\n",
        "    ####################### YOUR CODE ##########################\n",
        "    # TODO: encoded_input\n",
        "    # Combine title and description for richer text representation\n",
        "    texts = [f\"{title} {desc}\" for title, desc in zip(x['title'], x['description'])]\n",
        "\n",
        "    # Encode the texts using the sentence transformer\n",
        "    embeddings = model.encode(texts, show_progress_bar=False)\n",
        "\n",
        "    # Return dictionary with encoded input and labels\n",
        "    d = {\n",
        "        'encoded_input': embeddings,\n",
        "        'label': x['label']\n",
        "    }\n",
        "    return d\n",
        "    ############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB836CIZqulu"
      },
      "outputs": [],
      "source": [
        "########### PUT YOUR MODEL HERE ###########\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
        "###########################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQvqBakJjJ7b"
      },
      "outputs": [],
      "source": [
        "########### DO NOT CHANGE THIS CODE ###########\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    sen_model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
        "    # Prepare the dataset\n",
        "    tokenized_dataset = dataset.map(lambda x: encode_data(sen_model, x), batched=True)\n",
        "    print(tokenized_dataset['train'][100])\n",
        "    X_train = np.stack([np.array(x['encoded_input']) for x in tokenized_dataset['train']])\n",
        "    X_val = np.stack([np.array(x['encoded_input']) for x in tokenized_dataset['validation']])\n",
        "    y_train = np.stack([np.array(x['label']) for x in tokenized_dataset['train']])\n",
        "    y_val = np.stack([np.array(x['label']) for x in tokenized_dataset['validation']])\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(X_val.shape)\n",
        "    print(y_train.shape)\n",
        "    print(y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk2cKDK_bk_y"
      },
      "outputs": [],
      "source": [
        "########### COMPLETE THE FOLLOWING LOGISTIC REGRESSION CODE ###########\n",
        "if __name__ == \"__main__\":\n",
        "    # Train the logistic regression classifier on encoded training data\n",
        "    print(\"Training Logistic Regression classifier...\")\n",
        "    classifier = LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        C=1.0,\n",
        "        solver='lbfgs',\n",
        "        multi_class='multinomial',\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Fit the classifier\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_accuracy = classifier.score(X_val, y_val)\n",
        "    print(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Generate predictions on test set\n",
        "    test_preds = classifier.predict(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_j3mx8IMvNG"
      },
      "outputs": [],
      "source": [
        "######################## TO SUBMIT ########################\n",
        "if __name__ == \"__main__\":\n",
        "    # Save the trained model\n",
        "    model_path = f\"{SAVE_PATH}/sentence_encoder_classification.pkl\"\n",
        "    tiny_bert_prediction_path = f\"{SAVE_PATH}/part1_tiny_bert_model_test_prediction.csv\"\n",
        "    hf_bert_prediction_path = f\"{SAVE_PATH}/part1_hf_bert_model_test_prediction.csv\"\n",
        "    joblib.dump(classifier, model_path)\n",
        "    joblib.dump(test_preds, tiny_bert_prediction_path)\n",
        "    joblib.dump(test_preds, hf_bert_prediction_path)\n",
        "    print(f\"Saved model to {model_path}\")\n",
        "    print(f\"Saved predictions to {tiny_bert_prediction_path}\")\n",
        "    print(f\"Saved predictions to {hf_bert_prediction_path}\")\n",
        "    # test if it loads as expected\n",
        "    loaded_model = joblib.load(f\"{SAVE_PATH}/sentence_encoder_classification.pkl\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}