{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfraAd/CSC413-Homeworks/blob/main/Fall25_Hw8_transformer_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV4g7YkC25iC"
      },
      "source": [
        "# Homework 8\n",
        "\n",
        "In this homework, you will train a multi-label text classifier on a subset of [AG News](https://huggingface.co/datasets/r-three/ag_news_subset) dataset using a pre-trained BERT model. The AG News dataset consists of news articles categorized into one of four topics (0 - World, 1 - Sports, 2 - Business, 3 - Sci/Tech).\n",
        "\n",
        "**In part 1**, you will fine-tune a BERT-style model on the AG News dataset and evaluate its performance. You can find a tutorial for loading BERT and fine-tuning [here](https://huggingface.co/docs/transformers/training). For simplicity, I recommend using the [Hugging Face Transformers library](https://huggingface.co/docs/transformers/index).You're welcome to use a different framework if you prefer.\n",
        "\n",
        "**In part 2**, instead of fine-tuning a BERT-style model directly, you will use the representations from the BERT-style model as input to a linear classifier. Does this approach perform better or worse?\n",
        "\n",
        "For both part 1 and part 2, your goal is to achieve a test accuracy above the specified thresholds. You won’t have access to the test labels—just like in real-world applications!\n",
        "\n",
        "**Tips about fine-tuning**\n",
        "\n",
        "* Data preprocessing: raw text data should be tokenized before being fed to the model as batches during trainig.\n",
        "* Hyperparameter choices: Experiment with settings such as learning rate, warmup ratio, optimizer, number of training steps, and batch size.\n",
        "* Avoid overfitting: remember that your fine-tuned model will be evaluated on the test set!\n",
        "\n",
        "\n",
        "**!! IMPORTANT NOTE !!**\n",
        "\n",
        "You are free to explore and implement the training code however you want to maximize the model performance. However, please put the code you're running under `if __name__ == '__main__':` so that the particular training step is not run when we later evaluate your final script! Otherwise you may fail the Markus tests due to timeout.\n",
        "\n",
        "```\n",
        "if __name__ == '__main__':\n",
        "    # your training code to fine-tune the model\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYmukJqi_qQl"
      },
      "source": [
        "# Part 1 (4 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "edPVKxZtQ0u2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # !pip install datasets\n",
        "    # !pip install evaluate\n",
        "    # !pip install -U sentence-transformers\n",
        "\n",
        "    from datasets import load_dataset, DatasetDict\n",
        "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch\n",
        "    import evaluate\n",
        "\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    import joblib\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "    ################# Import additional packages you need #################\n",
        "    #####################################################################################\n",
        "    import numpy as np\n",
        "    import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lwHmIaTUQZYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c266554b-1bae-4f91-f776-c86e6ccfb20d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "################## HELPER CODE FOR SAVING RELEVANT FILES ##################\n",
        "if __name__ == '__main__':\n",
        "    def in_colab():\n",
        "        try:\n",
        "            import google.colab\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "\n",
        "    if in_colab():\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        SAVE_PATH = '/content/drive/MyDrive/CSC413'\n",
        "    else:\n",
        "        SAVE_PATH = '.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MenK8lkBOq3g"
      },
      "source": [
        "## Part 1.a\n",
        "\n",
        "Fine-tune [TinyBERT](https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D) on AG News and evaluate the results. You can find a tutorial for loading BERT and fine-tuning [here](https://huggingface.co/docs/transformers/training). In that tutorial, you will need to change the dataset from `\"yelp_review_full\"` to the correct dataset path and the model from `\"bert-base-uncased\"` to `\"huawei-noah/TinyBERT_General_4L_312D\"`. You'll also need to modify the code since AG New is a four-class classification dataset (unlike the Yelp Reviews dataset, which is a five-class classification dataset).\n",
        "\n",
        "**TODO**\n",
        "* After fine-tuning the model, save model predictions on the test set to *part1_tiny_bert_model_test_prediction.csv*. The csv file should contain \"index\" columns, corresponding to the unique sample index, and \"pred\" column, the model prediction on that sample. Your model should achieve >= 80% on the test accuracy to receive a full mark.\n",
        "\n",
        "```\n",
        "index, pred\n",
        "0,model_pred_value_0\n",
        "1,model_pred_value_1\n",
        "2,model_pred_value_2\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R3Zr_lHDWVTU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c35638d65cf14e65a80ee5a4d5876f9a",
            "77068d2122f044de9286e8998cd5b48e",
            "d5a3b8670aa74ca58282aedda0fb298a",
            "a34133b59cbf4cd9964b02f722171777",
            "083fc9a2712f4b9ba283b1feabcc9deb",
            "55ddeb6c8492498ca38025f44305daf4",
            "d9286fc8f0c94c66bcf66c1f4cf0fe10",
            "e59fd6bb484445c68e227ac8d5f3d21d",
            "69ab50bcd7e1499a8cc3a248156604ae",
            "9624cd858f794c9b88362e99ed13b3d8",
            "9304509bf9594f38b12b0708456840b3",
            "57fdc58381b8400a9da6527d56693e7b",
            "b67adf93261f4b24840892c578e27eb3",
            "75f4eeb4a34d4814a847745670c6aefa",
            "2c442c9310314abf9e45012feb326420",
            "5a86118389c34a7db39a80e385271742",
            "8a431295fac541d292f0ccdd9e86b2f3",
            "4559391bb6fb47b59043eec5f6e8c1e2",
            "f7efdd743e6747b99bf781ec03ceb87d",
            "cbe30161f99640ef9fe65d6f79d14dfe",
            "9bfc7c2a05914a5b82b5991ff04753ba",
            "a1bb4c446f874562b369aa53e3524477",
            "518b1cf22674418c8c4fc99eebeb5118",
            "1e912c17038f41249d11f1ba6dc94dd5",
            "4b92faec91294409b2b14eefc8deffae",
            "0dea1bac60d149ebaffc2301d14b523d",
            "8b449345ed5045b59e7aa2b0332182e2",
            "f24cfd7164594078a67ebe0f6dbb745b",
            "cfd7d6a1dbb64f4ab5eb7fab29a73831",
            "272c7f764ac04e0b9e0c19623a8a4cf1",
            "1f3092983b434b8a9222b80c721123a5",
            "bcf34672b55049d699f5791c4f30b644",
            "071ded24a4744000954caa3fe189f036"
          ]
        },
        "outputId": "88c617cc-4a2c-447e-bd20-8e9cfbd04732"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'label': 3, 'title': 'Microsoft Takes Giant Step against Spyware', 'description': 'Microsoft has beefed up its security portfolio by purchasing anti-spyware specialist Giant Company Software. A test version of a spyware protection, detection and removal tool based on Giant #39;s ', 'index': 100}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c35638d65cf14e65a80ee5a4d5876f9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57fdc58381b8400a9da6527d56693e7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "518b1cf22674418c8c4fc99eebeb5118",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-668314641.py:40: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mafra-azad\u001b[0m (\u001b[33mafra-azad-university-of-toronto\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251102_183221-nidbyrme</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/afra-azad-university-of-toronto/huggingface/runs/nidbyrme' target=\"_blank\">worldly-thunder-3</a></strong> to <a href='https://wandb.ai/afra-azad-university-of-toronto/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/afra-azad-university-of-toronto/huggingface' target=\"_blank\">https://wandb.ai/afra-azad-university-of-toronto/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/afra-azad-university-of-toronto/huggingface/runs/nidbyrme' target=\"_blank\">https://wandb.ai/afra-azad-university-of-toronto/huggingface/runs/nidbyrme</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 00:51, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.645760</td>\n",
              "      <td>0.807000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.423495</td>\n",
              "      <td>0.865000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.379353</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.539200</td>\n",
              "      <td>0.392662</td>\n",
              "      <td>0.869000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-668314641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Train and save predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4566\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4567\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4568\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4569\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4705\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4706\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4707\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4708\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4709\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   3098\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m         \"\"\"\n\u001b[0;32m-> 3100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_fp32_wrapper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_torch_compile\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDistributedOperationException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{function.__module__}.{function.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     return recursively_apply(\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Gather all sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# Then pad to the maximum size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "######################## DO NOT MODIFY THE CODE ########################\n",
        "if __name__ == '__main__':\n",
        "    dataset = load_dataset('r-three/ag_news_subset')\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\", num_labels=4)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
        "    print(dataset[\"train\"][100])\n",
        "\n",
        "    # Tokenization function\n",
        "    def tokenize_function(examples):\n",
        "        texts = [f\"{title} {desc}\" for title, desc in zip(examples['title'], examples['description'])]\n",
        "        return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # Tokenize datasets\n",
        "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    # Metrics\n",
        "    accuracy_metric = evaluate.load(\"accuracy\")\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"{SAVE_PATH}/tinybert_results\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=5e-5,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=64,\n",
        "        num_train_epochs=4,\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        save_strategy = \"epoch\"\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # Train and save predictions\n",
        "    trainer.train()\n",
        "    test_predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "    test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
        "\n",
        "    pd.DataFrame({'index': range(len(test_preds)), 'pred': test_preds}).to_csv(\n",
        "        f\"{SAVE_PATH}/part1_tiny_bert_model_test_prediction.csv\", index=False\n",
        "    )\n",
        "#########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your prediction is saved in pandas dataframe, you can do something like:\n",
        "```\n",
        "if __name__ == '__main__':\n",
        "   part1_tiny_bert_pred.to_csv(f\"{SAVE_PATH}/part1_tiny_bert_model_test_prediction.csv\", index=False)\n",
        "```"
      ],
      "metadata": {
        "id": "SHieq6Luch21"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JTLJgvUIT46"
      },
      "source": [
        "## Part 1.b\n",
        "\n",
        "For this section, choose a different pre-trained BERT-style model from the [Hugging Face Model Hub](https://huggingface.co/models) and fine-tune it. There are tons of options - part of the homework is navigating the hub to find different models! I recommend picking a model that is smaller than BERT-Base (as TinyBERT is) just to make things computationally cheaper. Is the final validation accuracy higher or lower with this other model?\n",
        "\n",
        "**TODO**\n",
        "* As in part 1.a, save model predictions on the test set to *part1_hf_bert_model_test_prediction.csv*. The csv file should contain \"index\" columns, corresponding to the unique sample index, and \"pred\" column, the model prediction on that sample. Your model should achieve >=80% on the test accuracy to receive a full mark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAw02tJzJDme"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    ############### YOUR CODE ###############\n",
        "    # TODO: find a new HF BERT based model from HuggingFace and load it.\n",
        "    HF_BERT_BASED_MODEL = 'distilbert-base-uncased'\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    print(f\"Loading model: {HF_BERT_BASED_MODEL}\")\n",
        "    model_hf = AutoModelForSequenceClassification.from_pretrained(HF_BERT_BASED_MODEL, num_labels=4)\n",
        "    tokenizer_hf = AutoTokenizer.from_pretrained(HF_BERT_BASED_MODEL)\n",
        "\n",
        "    # Tokenization function for the new model\n",
        "    def tokenize_function_hf(examples):\n",
        "        texts = [f\"{title} {desc}\" for title, desc in zip(examples['title'], examples['description'])]\n",
        "        return tokenizer_hf(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # Tokenize datasets\n",
        "    print(\"Tokenizing datasets with new tokenizer...\")\n",
        "    tokenized_datasets_hf = dataset.map(tokenize_function_hf, batched=True)\n",
        "\n",
        "    # Data collator\n",
        "    data_collator_hf = DataCollatorWithPadding(tokenizer=tokenizer_hf)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args_hf = TrainingArguments(\n",
        "        output_dir=f\"{SAVE_PATH}/hf_bert_results\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=3e-5,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=64,\n",
        "        num_train_epochs=3,\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        logging_steps=100,\n",
        "        save_total_limit=2,\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer_hf = Trainer(\n",
        "        model=model_hf,\n",
        "        args=training_args_hf,\n",
        "        train_dataset=tokenized_datasets_hf[\"train\"],\n",
        "        eval_dataset=tokenized_datasets_hf[\"validation\"],\n",
        "        tokenizer=tokenizer_hf,\n",
        "        data_collator=data_collator_hf,\n",
        "        compute_metrics=compute_metrics,  # Reuse from Part 1.a\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    print(f\"Training {HF_BERT_BASED_MODEL}...\")\n",
        "    trainer_hf.train()\n",
        "\n",
        "    # Evaluate\n",
        "    eval_results_hf = trainer_hf.evaluate()\n",
        "    print(f\"Validation Accuracy: {eval_results_hf['eval_accuracy']:.4f}\")\n",
        "\n",
        "    # Predict on test set\n",
        "    print(\"Generating predictions on test set...\")\n",
        "    test_predictions_hf = trainer_hf.predict(tokenized_datasets_hf[\"test\"])\n",
        "    test_preds_hf = np.argmax(test_predictions_hf.predictions, axis=1)\n",
        "\n",
        "    # Save predictions to CSV\n",
        "    part1_hf_bert_pred = pd.DataFrame({\n",
        "        'index': range(len(test_preds_hf)),\n",
        "        'pred': test_preds_hf\n",
        "    })\n",
        "    part1_hf_bert_pred.to_csv(f\"{SAVE_PATH}/part1_hf_bert_model_test_prediction.csv\", index=False)\n",
        "    print(f\"Saved predictions to {SAVE_PATH}/part1_hf_bert_model_test_prediction.csv\")\n",
        "    #########################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your training code here...**"
      ],
      "metadata": {
        "id": "QP_4e2M4cSz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, you can consider something like:\n",
        "\n",
        "```\n",
        "if __name__ == '__main__':\n",
        "   part1_hf_bert_pred.to_csv(f\"{SAVE_PATH}/part1_hf_bert_model_test_prediction.csv\", index=False)\n",
        "```"
      ],
      "metadata": {
        "id": "jOyGA96Dc65h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yt5QSetH7Vu"
      },
      "source": [
        "# Part 2 (2.5 points)\n",
        "\n",
        "Instead of fine-tuning the full model on a target dataset, it's also possible to use the output representations from a BERT-style model as input to a linear classifier and *only* train the classifier (leaving the rest of the pre-trained parameters fixed). You can do this easily using the [`sentence-transformers`](https://www.sbert.net/) library. Using `sentence-tranformers` gives you back a fixed-length representation of a given text sequence. To achieve this, you need to\n",
        "1. Pick a pre-trained sentence Transformer.\n",
        "2. Load the AG News dataset and feed the text from each example into the model.\n",
        "3. Train a linear classifier on the representations.\n",
        "4. Evaluate performance on the validation set.\n",
        "\n",
        "For the second step, you can learn more about how to use Hugging Face datasets [here](https://huggingface.co/docs/datasets/index). For the third and fourth step, it's possible to either do this directly in PyTorch, or collect the learned representations and use them as feature vectors to train a linear classifier in any other library (e.g. [scikit-learn](https://scikit-learn.org/stable/modules/linear_model.html)). For this homework, you will implement the second approach.\n",
        "\n",
        "After you complete the above steps, is the accuracy on the validation set higher or lower using a fixed sentence Transformer?\n",
        "\n",
        "**TODO**:\n",
        "* Complete the `encode_data` function: the function embeds each text sample into an output representation using the provided sentence encoder. The function is called to map a text data sample to the model representation, as shown below:\n",
        "```\n",
        "dataset.map(lambda x: encode_data(sen_model, x), batched=True)\n",
        "```\n",
        "* Train a Logistic Regression classifier: use sklearn.linear_model.LogisticRegression to fit the model on the encoded text data.\n",
        "* Save your trained model: After training, saved teh fitted logistic regression model as `sentence_encoder_classification.pkl`. Your model should achieve >=85% on the test accuracy to receive a full mark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cym2hkG1WbVE"
      },
      "outputs": [],
      "source": [
        "def encode_data(model, x):\n",
        "    \"\"\"Takes the model and the dataset object\n",
        "        Returns a dictionary consisting of \"encoded_input\" and \"label\" as keys.\n",
        "        - \"encoded_input\" contains the tokenized text features produced by the sentence transformer.\n",
        "        - \"label\" is the target class label for each example.\n",
        "        encoded_input is the encoded text input, and label is the target label.\n",
        "        NOTE: Please assume the dataset object is the original one loaded via\n",
        "              load_dataset('r-three/') for reproducibility.\n",
        "              Which means if you want to create additional features to create the encoded_input,\n",
        "              do so within this function.\n",
        "    \"\"\"\n",
        "    ####################### YOUR CODE ##########################\n",
        "    # TODO: encoded_input\n",
        "    # Combine title and description for richer text representation\n",
        "    texts = [f\"{title} {desc}\" for title, desc in zip(x['title'], x['description'])]\n",
        "\n",
        "    # Encode the texts using the sentence transformer\n",
        "    embeddings = model.encode(texts, show_progress_bar=False)\n",
        "\n",
        "    # Return dictionary with encoded input and labels\n",
        "    d = {\n",
        "        'encoded_input': embeddings,\n",
        "        'label': x['label']\n",
        "    }\n",
        "    return d\n",
        "    ############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB836CIZqulu"
      },
      "outputs": [],
      "source": [
        "########### PUT YOUR MODEL HERE ###########\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
        "###########################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQvqBakJjJ7b"
      },
      "outputs": [],
      "source": [
        "########### DO NOT CHANGE THIS CODE ###########\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    sen_model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
        "    # Prepare the dataset\n",
        "    tokenized_dataset = dataset.map(lambda x: encode_data(sen_model, x), batched=True)\n",
        "    print(tokenized_dataset['train'][100])\n",
        "    X_train = np.stack([np.array(x['encoded_input']) for x in tokenized_dataset['train']])\n",
        "    X_val = np.stack([np.array(x['encoded_input']) for x in tokenized_dataset['validation']])\n",
        "    y_train = np.stack([np.array(x['label']) for x in tokenized_dataset['train']])\n",
        "    y_val = np.stack([np.array(x['label']) for x in tokenized_dataset['validation']])\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(X_val.shape)\n",
        "    print(y_train.shape)\n",
        "    print(y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk2cKDK_bk_y"
      },
      "outputs": [],
      "source": [
        "########### COMPLETE THE FOLLOWING LOGISTIC REGRESSION CODE ###########\n",
        "if __name__ == \"__main__\":\n",
        "    # Train the logistic regression classifier on encoded training data\n",
        "    print(\"Training Logistic Regression classifier...\")\n",
        "    classifier = LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        C=1.0,\n",
        "        solver='lbfgs',\n",
        "        multi_class='multinomial',\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Fit the classifier\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_accuracy = classifier.score(X_val, y_val)\n",
        "    print(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Generate predictions on test set\n",
        "    test_preds = classifier.predict(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_j3mx8IMvNG"
      },
      "outputs": [],
      "source": [
        "######################## TO SUBMIT ########################\n",
        "if __name__ == \"__main__\":\n",
        "    # Save the trained model\n",
        "    model_path = f\"{SAVE_PATH}/sentence_encoder_classification.pkl\"\n",
        "    tiny_bert_prediction_path = f\"{SAVE_PATH}/part1_tiny_bert_model_test_prediction.csv\"\n",
        "    hf_bert_prediction_path = f\"{SAVE_PATH}/part1_hf_bert_model_test_prediction.csv\"\n",
        "    joblib.dump(classifier, model_path)\n",
        "    joblib.dump(test_preds, tiny_bert_prediction_path)\n",
        "    joblib.dump(test_preds, hf_bert_prediction_path)\n",
        "    print(f\"Saved model to {model_path}\")\n",
        "    print(f\"Saved predictions to {tiny_bert_prediction_path}\")\n",
        "    print(f\"Saved predictions to {hf_bert_prediction_path}\")\n",
        "    # test if it loads as expected\n",
        "    loaded_model = joblib.load(f\"{SAVE_PATH}/sentence_encoder_classification.pkl\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c35638d65cf14e65a80ee5a4d5876f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77068d2122f044de9286e8998cd5b48e",
              "IPY_MODEL_d5a3b8670aa74ca58282aedda0fb298a",
              "IPY_MODEL_a34133b59cbf4cd9964b02f722171777"
            ],
            "layout": "IPY_MODEL_083fc9a2712f4b9ba283b1feabcc9deb"
          }
        },
        "77068d2122f044de9286e8998cd5b48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ddeb6c8492498ca38025f44305daf4",
            "placeholder": "​",
            "style": "IPY_MODEL_d9286fc8f0c94c66bcf66c1f4cf0fe10",
            "value": "Map: 100%"
          }
        },
        "d5a3b8670aa74ca58282aedda0fb298a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e59fd6bb484445c68e227ac8d5f3d21d",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69ab50bcd7e1499a8cc3a248156604ae",
            "value": 4000
          }
        },
        "a34133b59cbf4cd9964b02f722171777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9624cd858f794c9b88362e99ed13b3d8",
            "placeholder": "​",
            "style": "IPY_MODEL_9304509bf9594f38b12b0708456840b3",
            "value": " 4000/4000 [00:01&lt;00:00, 2537.70 examples/s]"
          }
        },
        "083fc9a2712f4b9ba283b1feabcc9deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ddeb6c8492498ca38025f44305daf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9286fc8f0c94c66bcf66c1f4cf0fe10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e59fd6bb484445c68e227ac8d5f3d21d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69ab50bcd7e1499a8cc3a248156604ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9624cd858f794c9b88362e99ed13b3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9304509bf9594f38b12b0708456840b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57fdc58381b8400a9da6527d56693e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b67adf93261f4b24840892c578e27eb3",
              "IPY_MODEL_75f4eeb4a34d4814a847745670c6aefa",
              "IPY_MODEL_2c442c9310314abf9e45012feb326420"
            ],
            "layout": "IPY_MODEL_5a86118389c34a7db39a80e385271742"
          }
        },
        "b67adf93261f4b24840892c578e27eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a431295fac541d292f0ccdd9e86b2f3",
            "placeholder": "​",
            "style": "IPY_MODEL_4559391bb6fb47b59043eec5f6e8c1e2",
            "value": "Map: 100%"
          }
        },
        "75f4eeb4a34d4814a847745670c6aefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7efdd743e6747b99bf781ec03ceb87d",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbe30161f99640ef9fe65d6f79d14dfe",
            "value": 1000
          }
        },
        "2c442c9310314abf9e45012feb326420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bfc7c2a05914a5b82b5991ff04753ba",
            "placeholder": "​",
            "style": "IPY_MODEL_a1bb4c446f874562b369aa53e3524477",
            "value": " 1000/1000 [00:00&lt;00:00, 2103.48 examples/s]"
          }
        },
        "5a86118389c34a7db39a80e385271742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a431295fac541d292f0ccdd9e86b2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4559391bb6fb47b59043eec5f6e8c1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7efdd743e6747b99bf781ec03ceb87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe30161f99640ef9fe65d6f79d14dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bfc7c2a05914a5b82b5991ff04753ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1bb4c446f874562b369aa53e3524477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "518b1cf22674418c8c4fc99eebeb5118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e912c17038f41249d11f1ba6dc94dd5",
              "IPY_MODEL_4b92faec91294409b2b14eefc8deffae",
              "IPY_MODEL_0dea1bac60d149ebaffc2301d14b523d"
            ],
            "layout": "IPY_MODEL_8b449345ed5045b59e7aa2b0332182e2"
          }
        },
        "1e912c17038f41249d11f1ba6dc94dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f24cfd7164594078a67ebe0f6dbb745b",
            "placeholder": "​",
            "style": "IPY_MODEL_cfd7d6a1dbb64f4ab5eb7fab29a73831",
            "value": "Map: 100%"
          }
        },
        "4b92faec91294409b2b14eefc8deffae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_272c7f764ac04e0b9e0c19623a8a4cf1",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f3092983b434b8a9222b80c721123a5",
            "value": 2500
          }
        },
        "0dea1bac60d149ebaffc2301d14b523d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcf34672b55049d699f5791c4f30b644",
            "placeholder": "​",
            "style": "IPY_MODEL_071ded24a4744000954caa3fe189f036",
            "value": " 2500/2500 [00:01&lt;00:00, 2436.27 examples/s]"
          }
        },
        "8b449345ed5045b59e7aa2b0332182e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f24cfd7164594078a67ebe0f6dbb745b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd7d6a1dbb64f4ab5eb7fab29a73831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "272c7f764ac04e0b9e0c19623a8a4cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f3092983b434b8a9222b80c721123a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcf34672b55049d699f5791c4f30b644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071ded24a4744000954caa3fe189f036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}